Understood: we keep **Option 1** and **Approach A (build inside Docker)**, and **yes — Docker artifacts are generated by Archon** as part of the scaffold (not something the user hand-writes).

Here’s the clarified plan + the exact “what gets generated” contract.

---

# ✅ Clarified: Docker Pack is GENERATED (Approach A)

## Generator output must include (always, when `platform.docker=true`)

1. `Dockerfile`  ✅ **multi-stage build**
2. `docker-compose.yml` ✅ **api + postgres**
3. `.dockerignore`
4. `.env.docker` (or compose inline env; I recommend `.env.docker`)
5. `README.md` section: “Run with Docker”
6. Optional: `scripts/docker-up.sh` and `scripts/docker-down.sh`

No manual steps.

---

# What “Approach A” means concretely

### Build happens **inside** Docker

* The user does **not** need Node installed locally.
* Compose runs:

  * build API image
  * starts Postgres
  * starts API
  * healthchecks confirm readiness

### The only command the client runs

```bash
docker compose up --build
```

Then Swagger is available at:

* `http://localhost:3000/docs`

---

# Where it plugs in your pipeline

## Generation pipeline (your CLI “post-gen steps”)

### In `--qa` mode:

1. generate
2. prettier
3. lint
4. tests (optional)
5. `npm run build`
6. `docker build .` ✅
7. `docker compose up -d` ✅
8. curl `/health/ready` ✅
9. print swagger link ✅

### In non-QA mode:

* just generate the docker files
* user runs compose manually

This makes Docker part of the **product**, and QA part of **trust**.

---

# The “prompt” to encode (as a generator rule)

Use this exactly in Phase 2 later:

> **Docker Pack (Approach A) must be generated**
>
> * Generate a multi-stage `Dockerfile` that builds the NestJS app inside the container and runs `node dist/main.js` in the runtime stage.
> * Generate `docker-compose.yml` with `api` and `db` services.
> * `db` must use Postgres and include a healthcheck using `pg_isready`.
> * `api` must depend on `db` with health-based dependency and include a healthcheck hitting `GET /health/ready`.
> * Configure `DATABASE_URL` to point to the compose service hostname `db`.
> * Expose API on host port 3000 and ensure Swagger is available at `/docs`.
> * Generate `.dockerignore` and a README section with a single command: `docker compose up --build` and the Swagger URL.

---

# One small question you don’t need to answer (I’ll default)

Postgres port exposure:

* **Default (recommended):** DB internal only (no `5432:5432` published)
* You can add `expose: 5432` for internal networking (compose default already handles this)

I’ll implement the internal-only default in the templates.

Great — here are the **exact generated artifacts** for **Option 1 / Approach A (build inside Docker)**. These are template-ready and deterministic.

You’ll generate them into the project root (same level as `src/`, `package.json`).

---

# 1) `Dockerfile` (multi-stage build)

```dockerfile
# ---------- build stage ----------
FROM node:20-alpine AS build
WORKDIR /app

# Install deps first (better layer caching)
COPY package*.json ./
RUN npm ci

# Copy sources and build
COPY . .
RUN npm run build

# ---------- runtime stage ----------
FROM node:20-alpine AS runtime
WORKDIR /app

ENV NODE_ENV=production

# Install only production deps
COPY package*.json ./
RUN npm ci --omit=dev

# Copy built output
COPY --from=build /app/dist ./dist

# If you serve static assets later, copy them here too
# COPY --from=build /app/public ./public

EXPOSE 3000

# Run as non-root (nice security baseline)
RUN addgroup -S app && adduser -S app -G app
USER app

CMD ["node", "dist/main.js"]
```

✅ Build inside Docker
✅ Runtime image only has prod deps + dist
✅ Non-root user

---

# 2) `.dockerignore`

```gitignore
node_modules
dist
.git
.gitignore
.env
.env.*
npm-debug.log*
yarn.lock
pnpm-lock.yaml
.DS_Store
coverage
```

Note: we ignore `dist` because the build happens in Docker.

---

# 3) `.env.docker` (compose defaults)

```bash
NODE_ENV=development
PORT=3000
API_PREFIX=api/v1

# CORS
CORS_ORIGINS=http://localhost:3000

# Rate limiting
RATE_LIMIT_TTL=60
RATE_LIMIT_MAX=100

# Database (compose service hostname = db)
DATABASE_URL=postgresql://app:app@db:5432/app?schema=public

# Optional for hosted Postgres
# DATABASE_SSL=false

# Optional body size knob
MAX_BODY_SIZE=1mb
```

---

# 4) `docker-compose.yml` (api + db + healthchecks)

```yaml
services:
  db:
    image: postgres:16-alpine
    environment:
      POSTGRES_USER: app
      POSTGRES_PASSWORD: app
      POSTGRES_DB: app
    volumes:
      - db_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U app -d app"]
      interval: 5s
      timeout: 3s
      retries: 20

  api:
    build:
      context: .
      dockerfile: Dockerfile
    env_file:
      - .env.docker
    depends_on:
      db:
        condition: service_healthy
    ports:
      - "3000:3000"
    healthcheck:
      test: ["CMD-SHELL", "wget -qO- http://localhost:3000/health/ready || exit 1"]
      interval: 10s
      timeout: 3s
      retries: 20

volumes:
  db_data:
```

✅ DB internal-only (no `5432:5432`)
✅ API exposed on 3000
✅ Healthchecks:

* Postgres: `pg_isready`
* API: calls `/health/ready`

---

# 5) README section to generate

Add this block under “Run”:

````md
## Run with Docker

```bash
docker compose up --build
````

Then open:

* Swagger: [http://localhost:3000/docs](http://localhost:3000/docs)
* Health: [http://localhost:3000/health](http://localhost:3000/health)
* Readiness: [http://localhost:3000/health/ready](http://localhost:3000/health/ready)

````

---

# 6) Optional helper scripts (nice DX)

## `scripts/docker-up.sh`
```bash
#!/usr/bin/env bash
set -euo pipefail
docker compose up --build
````

## `scripts/docker-down.sh`

```bash
#!/usr/bin/env bash
set -euo pipefail
docker compose down -v
```

Make them executable in generation step:

```bash
chmod +x scripts/docker-up.sh scripts/docker-down.sh
```

---

# 7) One small wiring change in your `main.ts` (MAX_BODY_SIZE)

Since you now have `.env.docker` including `MAX_BODY_SIZE`, use it:

```ts
const maxBodySize = process.env.MAX_BODY_SIZE || "1mb";
app.useBodyParser("json", { limit: maxBodySize });
app.useBodyParser("urlencoded", { extended: true, limit: maxBodySize });
```

This keeps Docker and local runs consistent.

---

## Generator tasks (what to implement in Archon)

Add template outputs:

* root `Dockerfile`
* root `.dockerignore`
* root `docker-compose.yml`
* root `.env.docker`
* README block append or template section
* optional scripts in `scripts/`

And in `--qa` mode add:

* `docker build .`
* `docker compose up -d`
* curl `/health/ready`
* print Swagger URL

